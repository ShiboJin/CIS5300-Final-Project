{
  "best_global_step": 50,
  "best_metric": 0.5108442306518555,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 10,
  "global_step": 51,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 0.6593270301818848,
      "learning_rate": 0.0,
      "loss": 0.8478,
      "step": 1
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 0.6823710799217224,
      "learning_rate": 1.0000000000000001e-07,
      "loss": 0.8345,
      "step": 2
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 0.6445642709732056,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.8109,
      "step": 3
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 0.658588171005249,
      "learning_rate": 3.0000000000000004e-07,
      "loss": 0.841,
      "step": 4
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 0.6553186178207397,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.8305,
      "step": 5
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 0.6806453466415405,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.8612,
      "step": 6
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 0.6351439952850342,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.8361,
      "step": 7
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 0.6496403813362122,
      "learning_rate": 7.000000000000001e-07,
      "loss": 0.8145,
      "step": 8
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 0.66142737865448,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.8737,
      "step": 9
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.637456476688385,
      "learning_rate": 9.000000000000001e-07,
      "loss": 0.8266,
      "step": 10
    },
    {
      "epoch": 0.5882352941176471,
      "eval_loss": 0.5219007730484009,
      "eval_runtime": 6.7862,
      "eval_samples_per_second": 110.224,
      "eval_steps_per_second": 6.926,
      "step": 10
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 0.6671031713485718,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.8217,
      "step": 11
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 0.6588302850723267,
      "learning_rate": 1.1e-06,
      "loss": 0.8297,
      "step": 12
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 0.6360414624214172,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.8025,
      "step": 13
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 0.6505603194236755,
      "learning_rate": 1.3e-06,
      "loss": 0.8346,
      "step": 14
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 0.6718165874481201,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.826,
      "step": 15
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 0.6529962420463562,
      "learning_rate": 1.5e-06,
      "loss": 0.8125,
      "step": 16
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6774526238441467,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.8226,
      "step": 17
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 0.6481241583824158,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 0.8172,
      "step": 18
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 0.6455180048942566,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.7959,
      "step": 19
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.6543908715248108,
      "learning_rate": 1.9000000000000002e-06,
      "loss": 0.8339,
      "step": 20
    },
    {
      "epoch": 1.1764705882352942,
      "eval_loss": 0.5211808085441589,
      "eval_runtime": 6.697,
      "eval_samples_per_second": 111.692,
      "eval_steps_per_second": 7.018,
      "step": 20
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 0.6696067452430725,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.8419,
      "step": 21
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 0.6724938154220581,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 0.8174,
      "step": 22
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 0.7005655765533447,
      "learning_rate": 2.2e-06,
      "loss": 0.8559,
      "step": 23
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 0.6620829701423645,
      "learning_rate": 2.3000000000000004e-06,
      "loss": 0.8306,
      "step": 24
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 0.6687583327293396,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.8503,
      "step": 25
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 0.6889355182647705,
      "learning_rate": 2.5e-06,
      "loss": 0.8105,
      "step": 26
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 0.6755169630050659,
      "learning_rate": 2.6e-06,
      "loss": 0.8082,
      "step": 27
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 0.6867607831954956,
      "learning_rate": 2.7000000000000004e-06,
      "loss": 0.8305,
      "step": 28
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 0.6458684206008911,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.8068,
      "step": 29
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.6961092352867126,
      "learning_rate": 2.9e-06,
      "loss": 0.8257,
      "step": 30
    },
    {
      "epoch": 1.7647058823529411,
      "eval_loss": 0.519202709197998,
      "eval_runtime": 6.8005,
      "eval_samples_per_second": 109.992,
      "eval_steps_per_second": 6.911,
      "step": 30
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 0.6821191906929016,
      "learning_rate": 3e-06,
      "loss": 0.8602,
      "step": 31
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 0.6723085641860962,
      "learning_rate": 3.1000000000000004e-06,
      "loss": 0.8481,
      "step": 32
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 0.6751975417137146,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.8278,
      "step": 33
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.645904004573822,
      "learning_rate": 3.3000000000000006e-06,
      "loss": 0.817,
      "step": 34
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 0.7142819166183472,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.8548,
      "step": 35
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 0.6926746964454651,
      "learning_rate": 3.5e-06,
      "loss": 0.8442,
      "step": 36
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 0.7041411399841309,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.8497,
      "step": 37
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 0.7093605995178223,
      "learning_rate": 3.7e-06,
      "loss": 0.8355,
      "step": 38
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 0.6877169609069824,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.8265,
      "step": 39
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.683296799659729,
      "learning_rate": 3.900000000000001e-06,
      "loss": 0.8041,
      "step": 40
    },
    {
      "epoch": 2.3529411764705883,
      "eval_loss": 0.5156512260437012,
      "eval_runtime": 6.8949,
      "eval_samples_per_second": 108.486,
      "eval_steps_per_second": 6.817,
      "step": 40
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 0.7156030535697937,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.8274,
      "step": 41
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 0.6838039755821228,
      "learning_rate": 4.1e-06,
      "loss": 0.7919,
      "step": 42
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 0.6819983720779419,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.8031,
      "step": 43
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 0.7241236567497253,
      "learning_rate": 4.3e-06,
      "loss": 0.8173,
      "step": 44
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 0.6866757869720459,
      "learning_rate": 4.4e-06,
      "loss": 0.8149,
      "step": 45
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 0.7235890626907349,
      "learning_rate": 4.5e-06,
      "loss": 0.8302,
      "step": 46
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 0.7072960734367371,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.8104,
      "step": 47
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 0.713091254234314,
      "learning_rate": 4.7e-06,
      "loss": 0.7998,
      "step": 48
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 0.6782462000846863,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.7897,
      "step": 49
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.7151057124137878,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.8198,
      "step": 50
    },
    {
      "epoch": 2.9411764705882355,
      "eval_loss": 0.5108442306518555,
      "eval_runtime": 6.9739,
      "eval_samples_per_second": 107.257,
      "eval_steps_per_second": 6.739,
      "step": 50
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7292296886444092,
      "learning_rate": 5e-06,
      "loss": 0.8091,
      "step": 51
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 51,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1713987821436928e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
